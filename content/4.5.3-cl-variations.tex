
Three variations of the ``CL'' network were made.
The ``CML'' network simply adds a max pooling layer to the convolutional layer.

The ``CLL'' network increases the output units of the convolutional layer and adds a LSTM layer with 64 output units before the final LSTM layer with 3 outputs. This change gives more parameters to the LSTM part of the network.

The ``CLD'' network also tries to increase the influence of the LSTM layer in the network. It reduces the convolutional input window while increases the number of output units. The number of output units of the LSTM network is increased to 128 and a fully connected layer is used as output layer.

The results of the experiments with these variations is shown in table \ref{tab:carvingclvariations}.
Overall, this three variations produced better results than the ``CL'' network, as can be seen in figure \ref{fig:cl-variations}.

\begin{table*}[!ht]
    \centering
    \caption[CL variations]{Comparison of models that use convolutional layers and LSTM layers}
    \label{tab:carvingclvariations}
\begin{tabular}{r|r|r|r|r|r|r}
\hline
Name & Parameters & Blocks & Epochs & Time    & Training          & Validation          \\       
     &            &        &        &         &          accuracy &            accuracy \\ \hline\hline

CL      & 24663     & all   & 159   & 10m00s    & 0.83  & 0.789 \\\hline
CLL     & 287824    & all   & 108   & 10m04s    & 0.879 & 0.856 \\\hline
CML     & 262416    & all   & 137   & 10m03s    & 0.863 & 0.836 \\\hline
CLD     & 1246339   & all   & 73    & 8m48s     & 0.902 & 0.857 \\\hline
\end{tabular}
\end{table*}

\noindent
\begin{figure}[htb!]
\centering\includegraphics[width=0.50\textwidth]{content/CL-CLL-CML-CLD.png}
\caption[CL variations]{\label{fig:cl-variations}Comparison of models that use convolutional layers and LSTM layers - validation accuracy vs. time(minutes)}%
\end{figure}
