\levelB{Exploratory research of models based on accuracy}
\label{sec:evalmodels}

\levelC{Objective}
In this exploratory research, different neural networks are trained and validated
at the file type identification task. Their accuracy is then compared,
to identify which models should be considered or disregarded in the remaining phases.


\levelC{Sampling}
To select a sample instance from the Govdocs1 dataset, first a random file is selected among those available, without replacement. Then, a block from this file is randomly selected. After all files have participated in the process, the process may be repeated as long as necessary. This way, all files are considered and the classes are easily balanced.
This contrasts with the sampling technique applied in other works, where all the sectors are grouped together before sampling, which may lead to a imbalance between classes.

\levelC{Inputs}
%one-hot
The input features of the network for each instance is a 512x256 matrix representing only one block of 512 bytes of a random file of the dataset. Each of the 512 bytes is one-hot encoded, meaning that its value is converted into a vector with 256 elements, with only one of them set to 1, corresponding to the value of the byte, while the others are set to zero.

%8bits
% The input features of the network for each instance is a 512x8 matrix representing only one block of 512 bytes of a random file of the dataset. Each of the 512 bytes uses a custom encoding where each of the 8 bits of a byte is represented as -1 or 1, depending whether the bit is 0 or 1. During initial tests, this encoding was compared to three other encodings: one-hot encoding, 8 bits represented as 0 or 1\todo{include citation}, and 8 bits represented as [0,1] and [1,0] \cite{hiester_file_2018}. More research should be done in the future to determine the best of the four, but initial results suggest they have similar impact on the model accuracy. The one-hot encoding has the disadvantage of increasing the input matrix size by a factor of 32.

\levelC{Outputs}
The output of the network for a given instance is a vector with a size equal to the number of classes, subjected to a softmax function, which applies the exponential function on the vector and then normalizes it. Each value will represent the predicted probability that the instance belongs to a specific class.


\levelC{Models}
The networks under consideration used different combinations of convolutional, max pooling, LSTM, and fully connected layers,
%loss
applying categorical crossentropy as the loss function. Binary crossentropy and mean squared error were considered during initial tests, but categorical crossentropy gave faster training times.

Fourteen models participated in this evaluation. One of then is a simple single layer perceptron. Two of them use LSTM layers without convolutional layers, while 3 of them use convolutional layers without LSTM layers. Eight models combine convolutional layers and LSTM layers. Table \ref{tab:models} outline the parameters of the models, which can be analysed in more details in the code repository \todo{repository}. The convolutional layers do not use padding. 

\input{content/tables/4.0.1-models.tex}

%optimization
All the trainings use the Adam \cite{kingma_adam:_2014}
optimization algorithm to guide backpropagation, which was selected because it performed well in the preliminary results without fine tuning of parameters.

% Constraints
The models where trained with a time constraint of ten minutes, which was sufficient to compare their performance, even before reaching stagnation.

\levelC{Results}
%exp18
The two models that used LSTM layers without convolutional layers presented a slower learning in comparison with the others, as can be seen in table \todo{include learning curve}.

The remaining models after ten minutes already showed signs of being close to their limit.
Their accuracy results were in the 0.4-0.55 range. \todo{include accuracy bar plot, table and check the mentioned range}.

The best model, identified as ``CLD'', achieved an accuracy of 0.515.

To check if the two slower models could give better result if executed for a longer period, they were trained for 10 hours. The model identified as ``LD'', which uses a LSTM layer followed by a fully connected layer, was able to achieve 0.494 accuracy, while the other, ``LL'', achieved only 0.153.



%stagnation in learning with such short times, combined with low final accuracy suggests that the dataset present some patterns that are easily recognizable, while the rest of the dataset present a very hard classification task.

% \levelC{Limitations and threats to validity}
In this exploratory research, the models were not trained until reach stagnation of accuracy. This was initially done to identify which models would be most promising for future testing, but further attempts to tune layer types, quantity and parameters were insufficient to raise accuracy above the 0.4-0.55 range, which suggests that selection or tuning of models may not be best approach to improve results.



