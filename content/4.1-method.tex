% \todo[inline]{include method figure}

%\levelB{Dataset sampling}
This study uses the Govdocs1 dataset \cite{garfinkel_bringing_2009}, which was fully downloaded and then organized by file extension.
This dataset has files with 63 different extensions. The 33 extensions with less than 200 files were discarded, to ensure the training and validation dataset would have at least 100 files of each file type.
The  ``text'' and ``unk'' extensions were discarded because examination showed that files with these extensions use multiple formats and they do not correspond to a single file type.
The remaining 28 extensions are listed in Table \ref{tab:studiesfiletypes}.

To select a sample instance from the Govdocs1 dataset, first, a random file is selected among those available, without replacement. Then, a block from this file is randomly selected. After all files have participated in the process, the process may be repeated as long as necessary. This way, all files are considered and the classes are easily balanced.
This contrasts with the sampling technique applied in other works, where all the sectors are grouped before sampling, which may lead to an imbalance between classes.

%\levelB{Inputs}
The input features of the neural network for each instance are a 512x256 matrix representing only one block of 512 bytes of a random file of the dataset. Each of the 512 bytes is one-hot encoded, meaning that its value is converted into a vector with 256 elements, with only one of them set to 1, corresponding to the value of the byte, while the others are set to zero.

%\levelB{Outputs}
The output of the neural network for a given instance is a vector with a size equal to the number of classes, subject to a softmax function, which applies the exponential function on the vector and then normalizes it. Each value will represent the predicted probability that the instance belongs to a specific class.

%\levelB{Models}
The neural networks under consideration used different combinations of convolutional, max pooling, LSTM, and fully connected layers, applying categorical cross-entropy as the loss function. Binary cross-entropy and mean squared error were considered during initial tests, but categorical cross-entropy gave faster training times.

Fourteen neural network models participated in this evaluation.
Their names indicate the types of layers that compose their architecture, using the letter ``C'' to indicate a convolutional layer, ``D'' to indicate a dense layer, also called fully-connected, ``L'' to indicate an LSTM layer, and ``M'' to indicate a max pooling layer. The convolutional layers do not use padding.
Table \ref{tab:models} lists the parameters of the models, which can be analyzed in more detail in the code repository \footnote{http://github.com/atilaromero/carving-experiments}. One of then, ``D'' is a simple single-layer perceptron. Two of them, ``LD'' and ``LL'', use LSTM layers without convolutional layers, while three of them, ``CD'', ``CM'', and ``CCM'', use convolutional layers without LSTM layers. Eight models, ``CL'', ``CML'', ``CLL'', ``CLD'', ``CCL'', ``CCLL'', ``CMCML'', and ``CMCMLL'', combine convolutional layers and LSTM layers. 

\input{content/tables/4.0.1-models.tex}

%optimization
All the training sessions used the Adam \cite{kingma_adam:_2014}
optimization algorithm to guide backpropagation, which was selected because it showed good learning speed in the preliminary tests without requiring fine-tuning of parameters.

% Constraints
The models were trained until no further improvement was observed in the last 10 epochs, using categorical cross-entropy loss.

After the 14 models were compared, one of the models with best accuracy results and faster training time, ``CLD'', was chosen to have its results compared with other works, using a longer training session than those used to assess the 14 models.

Using this extended training parameters, the ``CLD'' model was trained with the 28 file types used in the first stage. Then, a different model was built from scratch using the same file types of each of the most recent works listed in Table \ref{tab:datacarvingstudies}: 
Hiester \cite{hiester_file_2018}, 
Chen \textit{et al.} \cite{chen_file_2018},
Wang \textit{et al.} \cite{wang_sparse_2018},
Wang \textit{et al.} \cite{wang_file_2018},
and
Vulinović \textit{et al.} \cite{vulinovic_neural_2019}.

This comparison has three important restrictions.
Chen used 4096 bytes for the block size, while this work used 512 bytes only.
Vulinović got an F1-score of 81\% for the Multilayer Perceptron (MLP) fed with byte histograms, a better result than the one obtained with a Convolutional Neural Network (CNN) fed with raw bytes, 61\%. But the comparison with the ``CLD'' model of this study was based on Vulinović results with the CNN, not the MLP, because it is a more similar solution, one that uses raw bytes instead of byte histograms. Additionally, his results use F1-score, while this work measured accuracy. 

