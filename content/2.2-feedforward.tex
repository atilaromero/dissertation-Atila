Multilayer Perceptron (MLP)\cite{rosenblatt_perceptron:_1958} is an feedforward artificial neural network with at least three layers where all layers are fully-connected, meaning that all nodes of a layer are connected to all nodes of the next.

Given enough labeled input samples, these networks can be trained to classify the inputs in a closed group of categories.

The output of each layer is the result of a matrix multiplication of the input and a set of weights plus a bias vector, as shown in equation \ref{eq:mpl}, where $y$ is the output vector of the layer, $x$ is the input vector, $W$ is the set of weights matrix and $b$ is the bias vector.

\begin{align}
\label{eq:mpl}     
y &= x W + b
\end{align}


The training consists in a search for the weights that would \todo{}