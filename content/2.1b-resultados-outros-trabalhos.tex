The early studies on data carving used private datasets, making it difficult to compare the results of different studies. In 2009, Garfinkel \textit{et al.} \cite{garfinkel_bringing_2009} published the Govdocs1 dataset with 1 million files (a small amount of those files was removed later, for legal reasons). While some of the later works on the field still use private datasets, the Govdocs1 dataset has become the most used choice in studies related to data carving.
Therefore, this related work summary focuses on studies on file fragment classification that used the Govdocs1 dataset.

Depending on the objective, the focus of each study may either be whole file classification or file fragment classification. The whole file classification is generally an easier task because most file types, even those with high entropy and low compression rates, have well-structured headers, with easily recognizable patterns.

Most of the early work in this field used some form of dimensionality reduction in the input data before performing classification, as byte frequency distribution, compression rate, and various statistical techniques. The usage of raw bytes as input is recently becoming more popular, especially in studies applying machine learning techniques, which seems to be a rising trend in the last ten years.

Axelsson \cite{axelsson_normalised_2010} used the normalized compression distance as an input feature to a kNN algorithm, picking pairs of 512-byte fragments, compressing them with the bzip2 algorithm and comparing the length of the results.
He got an average accuracy of around 34\% using 28 file types.

Fitzgerald \textit{et al.} \cite{fitzgerald_using_2012}  used an SVM classifier with various statistical measures as input features, including unigram and bigram histogram counts, Shannon entropy, and compression length.
Omitting the first and the last fragments of each file, they got an average accuracy of 49.1\% using 24 file types.

Beebe \textit{et al.} \cite{beebe_sceadan:_2013}
compared various measures of complexity and byte frequency distributions of 512-byte fragments as input features to an SVM algorithm. They used 8 data types, txt, base64, base85, urlencoded, fat fs data, ntfs fs data, ext fs data, aes256, and
30 file types
from the Govdocs1 dataset and some other sources (19 are at least partially from the Govdocs1 dataset). They got an average accuracy of 73.4\% combining unigram and bigrams as input features.

Chen \textit{et al.} \cite{chen_file_2018}
used a Convolutional Neural Network (CNN) with five convolutional layers and 3 fully connected layers to classify fragments of 4096 bytes, converting each fragment into a 64x64 grayscale picture.
They got an average accuracy of 70.9\% using 16 file types.

Hiester \cite{hiester_file_2018} apparently was the first to use an LSTM network to perform file fragment classification. He compared the results of three types of neural networks: feedforward, convolutional, and LSTM. He used four file types from the Govdocs1 dataset.
Each bit of a 512-byte fragment was translated into two features, resulting in 8192 features per block (512*8*2). The first and last sectors of each file in the training set were discarded. In the experiments, the datasets were limited to one gigabyte to fit in memory. He got an average accuracy of 98\% using an LSTM network, 73\% using CNN, and 76\% using MLP.

Wang \textit{et al.} \cite{wang_sparse_2018} 
used sparse dictionaries for n-grams to extract features of 512-byte fragments, using this as input to an SVM classifier.
They got an average accuracy of 61.3\% using 18 file types.

Wang \textit{et al.} \cite{wang_file_2018}  
compared CNN, SVM, kNN, and XGboost, with fragments of different sizes, converting each byte to a 256-length vector (one-hot encoding). The CNN combined three parallel convolutional layers of widths 4, 8 and 16.
They used 20 file types from the Govdocs1 dataset.
Using CNN, they got an average accuracy of around 68\% with 512-byte fragments, and around 78\% with 4096-byte fragments.

VulinoviÄ‡ \textit{et al.} \cite{vulinovic_neural_2019}
compared a CNN with MLP, using 512 raw bytes as the CNN input, and byte histograms as input to the MLP.
Using 18 file types, they got a macro average f1 score of 61\% using CNN and 81\% using MLP.

Table \ref{tab:datacarvingstudies} summarizes 
the results of file fragment classification studies using Govdocs1 dataset and table \ref{tab:studiesfiletypes}
lists the file types used in each study.

\input{content/tables/2.1b-others.tex}

\input{content/tables/4.0.1-studies-filetypes.tex}
