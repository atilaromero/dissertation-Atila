\section{Objective}
The objective of the experiments described in this section 
was to compare the training time of different neural network models, given an target accuracy level, at the filetype identification task.

\section{Methodology}

Minimize the training time is important when the task of create new models to new filetypes is delegated to the forensic examiners community, since they may not have expensive hardware or time to train a more demanding neural network.

For similar reasons, models that require too much tuning to perform well are undesirable, since it would require a higher knowledge and work from the forensic examiner.


%metricas
To find models with such requirements, each experiment use two stop conditions, a limit of 150 epochs or an accuracy of 90\% in the training set, whichever occurs first. These limits were established during the first preliminary results. 

All the experiments use the Adam
%%%%%
\todo{reference}
%https://arxiv.org/abs/1412.6980v8
%https://openreview.net/forum?id=ryQu7f-RZ
optimization algorithm to guide backpropagation, which was selected because it performed well in the preliminary results without requiring tuning the learning rate.

%modelos
Several different combinations of convolutional, maxpooling, LSTM, and fully connected layers were explored.

\section{Datasets}

Datasets for three different file types, JPG, PDF, and PNG, were obtained from online sources.

The PDF files were retrieved from http://arxiv.org/pdf/, which stores them using a sequential nomenclature. The training dataset uses the files 1904.10000.pdf to 1904.10099.pdf, development 1904.10100.pdf to 1904.10199.pdf, and test 1904.10200.pdf to 1904.10299.pdf. 

The JPG samples were obtained in ftp://ftp.inrialpes.fr/pub/lear/douze/data/jpg1.tar.gz \todo{reference}, and 100 images were assigned to training, 100 to development and the remaining 612 to test.
%If you use this dataset, please cite the following paper:
% Herve Jegou, Matthijs Douze and Cordelia Schmid
% "Hamming Embedding and Weak geometry consistency for large scale image search"
% Proceedings of the 10th European conference on Computer vision, October, 2008

The PGN images were obtained from \url{http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip}\todo{reference}, and 100 images were assignet to training, 100 to development and the remaining 700 to test.

%dataset paper: http://www.vision.ee.ethz.ch/~timofter/publications/Agustsson-CVPRW-2017.pdf
% @InProceedings{Agustsson_2017_CVPR_Workshops,
% author = {Agustsson, Eirikur and Timofte, Radu},
% title = {NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study},
% booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
% month = {July},
% year = {2017}
% }

\section{Environment}
The experiments did not take advantage of GPU acceleration and were  conducted on a single computer with 256GB of RAM and with 2 Intel\textregistered Xeon\textregistered E5-2630 v2 processors, with 6 cores each, with 2 hyper-threads per core, or 24 hyper-threads in total. 

The source code for the experiments is available at \url{http://github.com/atilaromero/ML}.

\section{Results}

\todo[inline]{Refactor experiments description}
\subsection{Experiments 1 to 6}

Experiments 1 to 6 use a limited dataset, with only 3 files as source. Each input to the network is a random sector from one of these files. During these first tests, different strategies to structure the tests were being tried, and that was their main contribution.

Table \ref{tab:carving1-6} gives a summary of the results of experiments 1 to 6. The ``C'', ``M'', ``L'', and ``D'' columns indicate the number of convolutional, maxpooling, LSTM and dense layers in each model structure.
\input{content/5.3-z-tab-carving1-6.tex}

Experiment 1 uses a convolutional layer of 16 units followed by a maxpooling layer, a LSTM layer of 16 units and a dense layer of 3 units.

Experiment 2 increases the number of convolutional layers, but it was unable to finish the training in less than 150 epochs.

Experiment 3 introduces the use of the ``fit\_generator'' function, which makes the sampling sectors from the training files easier, avoid manual counting of the epochs, uses callbacks, and uses the development dataset in validation.

Experiment 4 skips the initialization with ones that was being used in the LSTM layer at the previous experiments as an attempt to increase reproducibility. It also introduces periodic saving of TensorBoard data.

Experiment 5 skips the convolutional layer, but the resulting network was too slow to train.

Experiment 6 skips the maxpooling layer.

% \noindent
% \begin{algorithm}
% \begin{lstlisting}[language=Python, frame=single, numbers=left]
% last = l0 = tf.keras.layers.Input(shape=(512,256))
% last = Conv1D(16, (4,), padding="same", activation="relu")(last)
% last = MaxPooling1D(pool_size=(2,))(last)
% last = LSTM(16, return_sequences=False, dropout=0.5,
%             kernel_initializer=tf.keras.initializers.Ones())(last)
% last = Dense(3)(last)
% last = Activation('softmax')(last)

% model = tf.keras.Model([l0], last)
% \end{lstlisting}
% \caption{\label{alg:3-files-001}Experiment 3-files-001}
% \end{algorithm}


\subsection{Experiments 7 to 11}
Experiments 7 to 11 uses the 300 files from the test dataset as input, but only using the first 512 bytes of each selected file. The validation is performed using the development dataset, with another 300 files and and also using only the first 512 bytes.

All experiments of this set were able to reach the desired accuracy of 90\% in a few epochs. This can be explained by the regularity in the structure which is a characteristic of the beginning of the files.

Table \ref{tab:carving7-11} gives a summary of the results of experiments 7 to 11. The ``C'', ``R'', ``L'', and ``D'' columns indicate the number of convolutional, recurrent, LSTM and dense layers in each model structure.
\input{content/5.3-z-tab-carving7-11.tex}

Experiment 7 uses almost the same code of experiment 5, it is a single LSTM layer with 0.5 dropout and a output fully connected layer of 3 units, one for each filetype in consideration, PDF, JPG, and PNG.

Experiment 8 uses four RNN layers followed by a LSTM layer.

Experiment 9 is similar to the previous one, but uses only 1 RNN instead of 4.

Experiment 10 is the simplest network, only a fully connected layer with 131072 input units (512 bytes times 256 possible values using one hot encoding) and 3 output units. It was by far the fastest networking concerning training time, and was able to reach the desired accuracy in only one epoch.

Experiment 11 uses a convolutional layer without maxpooling with 32 input units, 3 output units, and a stride of 16 followed by a LSTM layer with 3 output units. Some other convolution sizes and strides were tried during the test development. A convolutional layer with 512 units of input would be equivalent to a fully connected layer, as no convolution would be performed.

\subsection{Experiments 12 to 27}

Experiments 12 to 27 use a random sector (512 bytes chunks) from each file, instead of only use the first one as was done in the previous set of experiments.

Table \ref{tab:carving12-27} gives a summary of the results of experiments 12 to 27. The ``C'', ``M'', ``L'', and ``D'' columns indicate the number of convolutional, maxpooling, LSTM and dense layers in each model structure.
\input{content/5.3-z-tab-carving12-27.tex}

Experiment 12 uses the simple single fully connected layer approach used in experiment 10, but the results were not as impressive as before. Two factors are considered to be responsible for such difference. While in the first sector is reasonable to find patterns in specific positions in relation to the beginning of the sector, this correspondence is not normally preserved in the remaining sectors. The second factor is that in files with low compression rates, as image files, the beginning of the file normally presents more recognizable patterns than the middle.

Experiments 14, 15, 17, 21, 22, 24, 25, 26, and 27 did not achieve the minimum desired performance, as they did not achieve 90\% accuracy in less than 150 epochs.

Experiments 14, 15, and 17 use variations of a dual layer network consisting of a convolutional layer followed by a LSTM layer.

Experiment 21 used a TimeDistributed Keras' layer with a fully connected layer inside, followed by two LSTM layers.

Experiment 22 used a convolutional layer followed by two LSTM layers, but the experiment was interrupted because the training performance was too slow, probably because the higher number of parameters when compared to experiment 13.

Experiment 24 uses four convolutional layers followed by a LSTM layer, and a fully connected layer after.

Experiments 25, 26, and 27 do not use LSTM. Experiment 25 uses a convolutional layer followed by a fully connected layer. Experiment 26 uses a convolutional layer followed by a maxpooling layer. Experiment 27 uses 2 convolutional layers and a maxpooling layer.

% 14) Conv1D(3, (32,), strides=16),  LSTM(3)
% 15) Conv1D(32, (32,), strides=32),  LSTM(3)
% 17) Conv1D(256, (16,), strides=16), LSTM(3)
%  21) TimeDistributed(Dense(32)), LSTM(64), LSTM(3)
%  22) Conv1D(128, (32,), strides=1), LSTM(64), LSTM(3)
%  24) 4 camadas de convolução, LSTM(32), Dense(3)

% 25) Conv1D(64,(64,),strides=8), Flatten(), Dense(3)
% 26) Conv1D(3, (32,), strides=1), MaxPooling1D(481)
% 27) 2 camadas de convolução, maxpooling, sem LSTM

Experiments 16 and 23 also did not achieve \%90 accuracy in 150 epochs, but their accuracy X time curve was similar to the one of experiment 13. This three experiments are one of the two groups which had acceptable performance.
Experiment 16 uses a convolutional layer with maxpooling followed by a LSTM layer. Experiment 23 uses a convolutional layer followed by a LSTM layer and a fully connected layer.
Experiment 13 uses a convolutional layer followed by two LSTM layers.

% 13) Conv1D(32, (32,), strides=32), LSTM(64), LSTM(3)
%  16) Conv1D(32, (32,), strides=32), maxpooling, LSTM(3)
%  23) Conv1D(256, (16,), strides=16), LSTM(128), Dense(3)

Experiments 18, 19 and 20 are the group that presented best training performance. They start with two convolutional layers, with a maxpooling layer after each one. Experiment 18 and 19 use essentially the same structure and finishes the network with a single LSTM layer, while experiment 20 finishes with two LSTM layers.

% 18) 2 camadas de convolução + maxpooling, LSTM(3)
% 19) mesma strutura de modelo
% 20) 2 camadas de convolução + maxpooling, LSTM(64), LSTM(3)

