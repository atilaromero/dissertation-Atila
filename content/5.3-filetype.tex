\section{Filetype identification}
The objective of the experiments described in this section was to investigate which neural network models would be more adequate to the filetype identification task and to be used in subsequent research stages.

The experiments did not take advantage of GPU acceleration and were  conducted on a single computer with 256GB of RAM and with 2 Intel\textregistered Xeon\textregistered E5-2630 v2 processors, with 6 cores each, with 2 hyper-threads per core, or 24 hyper-threads in total. 

All the experiments use the Adam
%%%%%
\todo{reference}
optimization algorithm to guide backpropagation.

Each experiment use two stop conditions, a limit of 150 epochs or an accuracy of 90\% in the training set, whichever occurs first.

\subsection{Datasets}

Datasets for three different file types, JPG, PDF, and PNG, were obtained from online sources.

The PDF files were retrieved from http://arxiv.org/pdf/, which stores them using a sequential nomenclature. The training dataset uses the files 1904.10000.pdf to 1904.10099.pdf, development 1904.10100.pdf to 1904.10199.pdf, and test 1904.10200.pdf to 1904.10299.pdf. 

The JPG samples were obtained in ftp://ftp.inrialpes.fr/pub/lear/douze/data/jpg1.tar.gz \todo{reference}, and 100 images were assigned to training, 100 to development and the remaining 612 to test.
%If you use this dataset, please cite the following paper:
% Herve Jegou, Matthijs Douze and Cordelia Schmid
% "Hamming Embedding and Weak geometry consistency for large scale image search"
% Proceedings of the 10th European conference on Computer vision, October, 2008

The PGN images were obtained from \url{http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip}\todo{reference}, and 100 images were assignet to training, 100 to development and the remaining 700 to test.

%dataset paper: http://www.vision.ee.ethz.ch/~timofter/publications/Agustsson-CVPRW-2017.pdf
% @InProceedings{Agustsson_2017_CVPR_Workshops,
% author = {Agustsson, Eirikur and Timofte, Radu},
% title = {NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study},
% booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
% month = {July},
% year = {2017}
% }

\subsection{Experiments 1 to 6}

Experiments 1 to 6 use a limited dataset, with only 3 files as source. Each input to the network is a random sector from one of these files. During these first tests, different strategies to structure the tests were being tried, and that was their main contribution.

Table \ref{tab:carving1-6} gives a summary of the results of experiments 1 to 6. The ``C'', ``M'', ``L'', and ``D'' columns indicate the number of convolutional, maxpooling, LSTM and dense layers in each model structure.
\input{content/5.3-z-tab-carving1-6.tex}

Experiment 1 uses a convolutional layer of 16 units followed by a maxpooling layer, a LSTM layer of 16 units and a dense layer of 3 units.

Experiment 2 increases the number of convolutional layers, but it was unable to finish the training in less than 150 epochs.

Experiment 3 introduces the use of the ``fit\_generator'' function, which makes the sampling sectors from the training files easier, avoid manual counting of the epochs, uses callbacks, and uses the development dataset in validation.

Experiment 4 skips the initialization with ones that was being used in the LSTM layer at the previous experiments as an attempt to increase reproducibility. It also introduces periodic saving of TensorBoard data.

Experiment 5 skips the convolutional layer, but the resulting network was too slow to train.

Experiment 6 skips the maxpooling layer.

% \noindent
% \begin{algorithm}
% \begin{lstlisting}[language=Python, frame=single, numbers=left]
% last = l0 = tf.keras.layers.Input(shape=(512,256))
% last = Conv1D(16, (4,), padding="same", activation="relu")(last)
% last = MaxPooling1D(pool_size=(2,))(last)
% last = LSTM(16, return_sequences=False, dropout=0.5,
%             kernel_initializer=tf.keras.initializers.Ones())(last)
% last = Dense(3)(last)
% last = Activation('softmax')(last)

% model = tf.keras.Model([l0], last)
% \end{lstlisting}
% \caption{\label{alg:3-files-001}Experiment 3-files-001}
% \end{algorithm}


\subsection{Experiments 7 to 11}
Experiments 7 to 11 uses the 300 files from the test dataset as input, but only using the first 512 bytes of each selected file. The validation is performed using the development dataset, with another 300 files and and also using only the first 512 bytes.

All experiments of this set were able to reach the desired accuracy of 90\% in a few epochs. This can be explained by the regularity in the structure which is a characteristic of the beginning of the files.

Table \ref{tab:carving7-11} gives a summary of the results of experiments 7 to 11. The ``C'', ``R'', ``L'', and ``D'' columns indicate the number of convolutional, recurrent, LSTM and dense layers in each model structure.
\input{content/5.3-z-tab-carving7-11.tex}

Experiment 7 uses almost the same code of experiment 5, it is a single LSTM layer with 0.5 dropout and a output fully connected layer of 3 units, one for each filetype in consideration, PDF, JPG, and PNG.

Experiment 8 uses four RNN layers followed by a LSTM layer.

Experiment 9 is similar to the previous one, but uses only 1 RNN instead of 4.

Experiment 10 is the simplest network, only a fully connected layer with 131072 input units (512 bytes times 256 possible values using one hot encoding) and 3 output units. It was by far the fastest networking concerning training time, and was able to reach the desired accuracy in only one epoch.

Experiment 11 uses a convolutional layer without maxpooling with 32 input units, 3 output units, and a stride of 16 followed by a LSTM layer with 3 output units. Some other convolution sizes and strides were tried during the test development. A convolutional layer with 512 units of input would be equivalent to a fully connected layer, as no convolution would be performed.

\subsection{Experiments 12 to 27}

Experiments 12 to 27 use a random sector (512 bytes chunks) from each file, instead of only use the first one as was done in the previous set of experiments.

Table \ref{tab:carving12-27} gives a summary of the results of experiments 12 to 27. The ``C'', ``M'', ``L'', and ``D'' columns indicate the number of convolutional, maxpooling, LSTM and dense layers in each model structure.
\input{content/5.3-z-tab-carving12-27.tex}

Experiment 12 uses the simple single fully connected layer approach used in experiment 10, but the results were not as impressive as before. Two factors are considered to be responsible for such difference. While in the first sector is reasonable to find patterns in specific positions in relation to the beginning of the sector, this correspondence is not normally preserved in the remaining sectors. The second factor is that in files with low compression rates, as image files, the beginning of the file normally presents more recognizable patterns than the middle.

13) Conv1D(32, (32,), strides=32), LSTM(64), LSTM(3)
16) Conv1D(32, (32,), strides=32), maxpooling, LSTM(3)
18) 2 camadas de convolução + maxpooling, LSTM(3)
19) mesma strutura de modelo
20) 2 camadas de convolução + maxpooling, LSTM(64), LSTM(3)
23) Conv1D(256, (16,), strides=16), LSTM(128), LSTM(3)

14) Conv1D(3, (32,), strides=16),  LSTM(3)
15) Conv1D(32, (32,), strides=32),  LSTM(3)
17) Conv1D(256, (16,), strides=16), LSTM(3)
21) TimeDistributed(Dense(32)), LSTM(64), LSTM(3)
22) Conv1D(128, (32,), strides=1), LSTM(64), LSTM(3)
24) 4 camadas de convolução, LSTM(32), Dense(3)
25) Conv1D(64,(64,),strides=8), Flatten(), Dense(3)
26) Conv1D(3, (32,), strides=1), MaxPooling1D(481)
27) 2 camadas de convolução, maxpooling, sem LSTM
