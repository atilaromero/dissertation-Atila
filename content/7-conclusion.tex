The research described in this study was divided in three parts.
In chapter \ref{sec:evalmodels}, during the search for the best model to classify file fragments, an apparent limit on how far this models could be improved was found. This limitation can be also observed in other works, since training the model ``CLD'' with the same file types used in those works resulted in accuracy values similar to theirs.

In chapter \ref{sec:numberofclasses}, the influence
In chapter \ref{sec:exprandom}

\todo[inline]{contibutions from chap4}
\todo[inline]{contibutions from chap5}
\todo[inline]{contibutions from chap6}

The portion of data that could be identified as containing structures was higher than expected. While some of the errors could be explained by the inability of the models to distinguish  high entropy data from random data, this could only explain about 1/3 of the observed errors (12.7\% out of 37\%).

This raises the question of whether the remaning 2/3 of errors could be explained by different file types using the same data structures. This error source comes from the practice of using the extension of the file as the class to each of its parts. An analogy with speech recognition would be to label each syllable of a spoken word using the word as its label and then try to predict the whole word using only a syllable.

Unfortunately, for the file fragmentation task, the potential labels for smaller parts may be less obvious than it is for speech recognition. The best-case scenario would be if the neural network itself could choose the labeling. But evaluating those predicted labels using labels of its own choosing would introduce bias, as it could prefer to create only easy labels.
% The statement that all file types are composed of ``data'' is correct, but it is unhelpful.

An additional contribution of this work is the availability of the source code used to generate the results, which is a feature that not all studies provide. It can be used as a basis of comparison in future researches, generating models with the same architecture of those presented here.