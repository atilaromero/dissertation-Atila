The results of this Chapter highlight the importance of the file types chosen to compose the dataset. File types that hold compressed data or images are harder do classify. This suggests that their entropy is a source of classification errors. This also may explain why previous works in the field have achieved different results but the ``CLD'' model was able to almost match their results, as shown in Figure 4.3.

\levelC{Accuracy vs. number of classes}

In Figure \ref{fig:nclasses}, a decreasing trend was observed. An increase in the number of classes appears to be correlated with a decrease in accuracy. Another relevant aspect of the graph is that the range of the results seems to be smaller when more classes are used.  

This pattern is understandable: as the number of classes grows, the harder the classification problem is, leading to a decrease in accuracy. Meanwhile, the individual contributions of each class to the overall result diminish, leading to a decrease in variation between the different results for a given number of classes.

This behavior is an important aspect to consider during the evaluation of file fragments studies. This observation is in agreement with Beebe \textit{et al.} \cite{beebe_sceadan:_2013} observation, that the studies that select fewer classes tend to yield higher results. 

Still, with 42\% \footnote{In the extended training session described in Chapter 4, a higher accuracy was obtained and 38\% of samples were misclassified, instead of 42\%.} of samples being misclassified when the number of classes is 28, the question of what are the error sources and how they can be addressed requires attention.

The number of possible combinations of file types to compose the datasets depends on the number of classes being considered. For 28 classes, there is only one possible combination, while for two classes there are 378. For intermediary values, the numbers are much higher, which is the number of possible combinations disregarding the order of the elements: $ \frac{28!}{(28-n)!n!}$. For 14 file types, there are 40,116,600 combinations. For this reason, the significance of the 5 samples diminishes for intermediary values.

\levelC{Accuracy of pairs of classes}

The accuracy of models trained with pairs of classes, shown in Figure \ref{fig:dual}, suggests a reverse correlation between entropy and accuracy. Generally, file types with higher entropy tend to have lower minima, with the GIF file type being a notable exception. Most of these files use some form of compression, as image files for example.

It was demonstrated that the accuracy of a new model may be manipulated by the selection of file types that will compose the dataset. The lines ``hard file types first'' and ``easy file types first'' of Figure \ref{fig:nclasses} were created using the order shown in Figure \ref{fig:dual}, resulting in lines that seem to be close to the minimum and maximum of the possible accuracy values. 

\levelC{Principal Component Analysis}

The usage of PCA on the 28x28 distance matrix produced a 2D projection where, as shown in figures \ref{fig:pca} and \ref{fig:pca2}, a group of file types that use compression or contains images are grouped near each other: 
``gif'',
``jpg'',
``pdf'',
``gz'',
``kmz'',
``dwf'',
``ppt'',
``swf'',
``png'',
``pptx'',
and ``pps''.

\levelC{Final considerations}


Answering the second research question ``\textbf{How does the accuracy of neural network models changes relative to the number of classes in file fragment classification?}'', 
it was observed that an increase in the number of extensions selected to compose the training tends to decrease accuracy and to decrease variation in results. But the number of classes alone is not as important as the type of extension selected: some file types when included in the experiment have a much higher negative impact than others. This observation was demonstrated in the ``hard file types first'' and ``easy file types first'' of Figure \ref{fig:nclasses}, where the file types selected to compose were intentionally chosen, once to degrade results and once to improve them.


File types that contain images or that use compression were identified as those that have the highest negative effect on results, which suggests that their entropy may contribute to the error.

% \levelB{Limitations, threats to validity and future work}
The number of samples taken was small when compared to the number of all possible file types combinations. This imposes a limit on the conclusions that can be reached, and this limitation is hard to overcome.

The group that emerged as file types that most degrade results are files that use compression or contain images. While they are known for their high entropy, no measure of entropy was used to reinforce this claim.
This aspect is addressed in the next chapter.
